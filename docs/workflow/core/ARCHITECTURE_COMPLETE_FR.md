# Documentation Compl√®te du Syst√®me de Workflow MediaPipe v4.1

## Table des Mati√®res

1. [Vue d'Ensemble du Workflow](#vue-densemble-du-workflow)
2. [Architecture Backend](#architecture-backend)
3. [Architecture Frontend](#architecture-frontend)
4. [Points d'Int√©gration](#points-dint√©gration)
5. [Structure des Fichiers](#structure-des-fichiers)
6. [Configuration et S√©curit√©](#configuration-et-s√©curit√©)
7. [Environnements Virtuels](#environnements-virtuels)
8. [Exemples d'Utilisation](#exemples-dutilisation)

---

## Vue d'Ensemble du Workflow

Le syst√®me de workflow MediaPipe est un pipeline de traitement vid√©o con√ßu pour automatiser l'analyse et le traitement de contenus vid√©o. Chaque √©tape est sp√©cialis√©e et utilise des environnements Python d√©di√©s pour optimiser les performances.

### Note de version (v4.2)

#### Nouvelles Fonctionnalit√©s
  - D√©codage r√©cursif des s√©quences doublement encod√©es (ex: `amp%3Bdl=0`)
  - Gestion avanc√©e des entit√©s HTML et caract√®res sp√©ciaux
  - Optimisation des param√®tres Dropbox avec gestion des doublons
  - Validation renforc√©e des URLs apr√®s normalisation
  - R√©duction de 30% des entr√©es en double dans l'historique
Int√©gration Source Webhook + CSVService : cha√Æne de donn√©es unifi√©e
  - **Webhook JSON** = unique point d‚Äôentr√©e (pas d‚ÄôAirtable/MySQL/CSV legacy en production).
  - `CSVService` orchestre toujours la lecture du Webhook, la d√©duplication et la persistance SQLite via `download_history_repository`.
  - Cache TTL configurable et retry automatique pour √©viter les trous d‚Äôexploitation.
  - Classification automatique des URLs (Dropbox direct, proxy PHP) avant lancement des workers.
  - Support proxy PHP pour s√©curit√© en production (pas de connexions directes Dropbox depuis le serveur).
  - Services historiques MySQL/Airtable d√©plac√©s dans `services/deprecated/` et conserv√©s uniquement pour r√©f√©rence.
- **Optimisations de Performance**
  - **√âtape 2** : Compression non destructive avec support GPU/CPU
  - **√âtape 5** : Mode CPU-only optimis√© avec 15 workers internes
  - **Monitoring** : Widget syst√®me avec mode r√©duit et mises √† jour optimis√©es
  - Validation renforc√©e des entr√©es utilisateur
  - Protection contre les attaques XSS avec √©chappement HTML syst√©matique
  - Gestion s√©curis√©e des fichiers temporaires
  - Protection contre les injections de chemins
  - V√©rification des permissions pour tous les acc√®s fichiers

#### S√©curit√© et Accessibilit√© (v4.2+)
- **XSS Frontend** : ‚úÖ **AUDIT COMPLET** - √âchappement syst√©matique via `DOMUpdateUtils.escapeHtml()` et `textContent` pour les logs dynamiques. Toutes injections XSS P0 corrig√©es (`apiService.js`, `popupManager.js`).
- **Focus Management** : ‚úÖ **AUDIT COMPLET** - Focus trap + restauration sur toutes les modales (statsViewer, reportViewer, diagnostics) impl√©ment√© et test√©.
- **Tests A11y** : ‚úÖ **AUDIT COMPLET** - Suite Node/ESM compl√®te (`test_dom_batcher_performance.mjs`, `test_focus_trap.mjs`) avec validation non-r√©gression.
- **Performance** : ‚úÖ **AUDIT COMPLET** - Regex pr√©-compil√©es dans `uiUpdater.js` via `_COMPILED_LOG_PATTERNS` pour logs volumineux.
- **Reduced Motion** : ‚úÖ **AUDIT COMPLET** - Support global `prefers-reduced-motion` dans `base.css`.

#### Support GPU STEP5 (v4.2) - Statut Actuel
- **Mode** : Optionnel et exp√©rimental (d√©sactiv√© par d√©faut)
- **Moteur √©ligible UNIQUEMENT** : InsightFace (d√©cision 2025-12-27)
- **Restriction** : Tous les autres moteurs forc√©s en CPU-only m√™me si GPU activ√©
- **Validation** : `Config.check_gpu_availability()` requis avant activation
- **Fallback** : Bascule automatique CPU si VRAM insuffisante

#### Corrections et Optimisations (v4.1)
- **√âtape 4 (Analyse Audio)** : 
  - Optimisations I/O avec extraction ffmpeg vers tmpfs (remplace MoviePy)
  - √âcriture JSON streaming pour r√©duire l'utilisation m√©moire
  - Diarisation GPU-first avec fallback CPU configurable
  - Optimisations PyTorch (inference_mode/no_grad)

- **√âtape 5 (Tracking)** :
  - Mode CPU-only par d√©faut avec 15 workers internes
  - Corrections de la barre de progression
  - Gestion am√©lior√©e des erreurs

- **Interface Utilisateur** :
  - Mode compact unifi√© pour toutes les √©tapes
  - Am√©lioration des performances de rendu
  - Meilleure accessibilit√© (ARIA, gestion du clavier)
  - **Timeline Connect√©e** : ‚úÖ **Pipeline visuel moderne complet** avec n≈ìuds connect√©s, spine lumineuse, micro-interactions premium et panneau de d√©tails contextuel (Phases 1-3 compl√©t√©es le 2026-01-20).
    - Phase 1 : Structure HTML/CSS avec variables Timeline et spine/connecteurs
    - Phase 2 : Transitions harmonis√©es et micro-interactions hover/focus-within  
    - Phase 3 : Panneau d√©tails contextuel (StepDetailsPanel.js), accessibilit√© WCAG compl√®te, tests frontend int√©gr√©s
  - **Panneau de logs en overlay** : ‚úÖ **Lightbox ind√©pendante** (Option A) sans layout shifting, centr√©e et responsive, pilot√©e par le toggle ‚Äúüìü Auto-ouverture des logs‚Äù dans Settings. Les s√©quences et l‚Äôauto-scroll respectent la pr√©f√©rence utilisateur via `getAutoOpenLogOverlay()`. La logique utilise `openPopupUI`/`closePopupUI` et le conteneur `.logs-overlay-container` est d√©tach√© du flux principal.

- **Archivage** :
  - G√©n√©ration de hash SHA-256 pour l'int√©grit√© des donn√©es
  - M√©tadonn√©es de provenance am√©lior√©es
  - Gestion efficace de l'espace disque

### R√©f√©rences compl√©mentaires
- Voir ¬´ Monitoring Syst√®me & Instrumentation API ¬ª : [SYSTEM_MONITORING_ENHANCEMENTS.md](SYSTEM_MONITORING_ENHANCEMENTS.md)
- Voir ¬´ Strat√©gie de tests (pytest + ESM/Node) ¬ª : [TESTING_STRATEGY.md](TESTING_STRATEGY.md)
- Voir ¬´ Diagnostics Syst√®me (API) ¬ª : [DIAGNOSTICS_FEATURE.md](DIAGNOSTICS_FEATURE.md)
- Voir ¬´ Instrumentation des API (measure_api + PerformanceService) ¬ª : [API_INSTRUMENTATION.md](API_INSTRUMENTATION.md)
- Voir `memory-bank/decisionLog.md` (18‚ÄØjanvier‚ÄØ2026) pour la suppression Smart Upload/Diagnostics UI.
### Pipeline de Traitement

```mermaid
graph TD
    A[Archives ZIP/RAR] --> B[√âtape 1: Extraction]
    B --> C[√âtape 2: Conversion Vid√©o]
    C --> D[√âtape 3: D√©tection de Sc√®nes]
    D --> E[√âtape 4: Analyse Audio]
    E --> F[√âtape 5: Suivi Vid√©o]
    F --> G[√âtape 6: R√©duction JSON]
    G --> H[√âtape 7: Finalisation]
    H --> I[R√©sultats Finaux]
```

**Historique SQLite (mise √† jour 2026-01-21)**  
- Persistance multi-process via `DownloadHistoryRepository` (base locale `download_history.sqlite3`, WAL activ√©).  
- Variables : `DOWNLOAD_HISTORY_DB_PATH` (chemin absolu) et `DOWNLOAD_HISTORY_SHARED_GROUP` (chgrp + chmod 664 des fichiers `.sqlite3`, `-wal`, `-shm`).  
- Script officiel : `scripts/migrate_download_history_to_sqlite.py [--dry-run]` pour convertir un ancien `download_history.json` avant suppression.  
- Fonctions cl√©s :
  - `CSVService.add_to_download_history_with_timestamp()` : `INSERT ... ON CONFLICT` conservant le timestamp le plus ancien.
  - `CSVService.save_download_history()` : d√©l√®gue √† `download_history_repository.replace_all()` pour les op√©rations globales.
  - `CSVService._migrate_legacy_history_json_to_sqlite_if_needed()` : ex√©cution automatique au d√©marrage si la base est vide.
- `FilesystemService.open_path_in_explorer()` applique des garde-fous stricts : ouverture autoris√©e uniquement si `ENABLE_EXPLORER_OPEN=1` (opt-in local), si un display (`DISPLAY`/`WAYLAND_DISPLAY`) est disponible, et si le chemin demand√© reste sous `CACHE_ROOT_DIR` (configurable, d√©faut `/mnt/cache`). En production/headless, l‚Äôouverture est refus√©e par d√©faut (`DISABLE_EXPLORER_OPEN=1` implicite).

### Description des √âtapes

#### √âtape 1 : Extraction d'Archives (`extract_archives.py`)
- **Objectif** : Extraction s√©curis√©e d'archives ZIP, RAR, TAR
- **Environnement** : `env/` (environnement principal)
- **Entr√©es** : Archives contenant le mot-cl√© "Camille"
- **Sorties** : Dossiers extraits dans `projets_extraits/`
- **S√©curit√©** : Protection contre path traversal, sanitisation des noms de fichiers
- **Fonctionnalit√©s** :
  - D√©tection automatique du format d'archive
  - Nettoyage et organisation des fichiers extraits
  - Suppression optionnelle des archives apr√®s extraction
  - Journalisation compl√®te des op√©rations de s√©curit√©

#### √âtape 2 : Conversion Vid√©o (`convert_videos.py`)
- **Objectif** : Normalisation des vid√©os √† 25 FPS
- **Environnement** : `env/` (environnement principal)
- **Entr√©es** : Fichiers vid√©o (.mp4, .mov, .avi, .mkv, .webm, .flv, .wmv)
- **Sorties** : Vid√©os converties √† 25 FPS
- **Technologies** : FFmpeg avec support GPU (NVIDIA) et CPU
- **Optimisations** :
  - Mode GPU exclusif pour de meilleures performances
  - Copie audio intelligente (fallback vers r√©-encodage si n√©cessaire)
  - Traitement s√©quentiel optimis√©

#### √âtape 3 : D√©tection de Sc√®nes (`run_transnet.py`)
- **Objectif** : Identification automatique des changements de sc√®ne
- **Environnement** : `transnet_env/` (sp√©cialis√© PyTorch)
- **Entr√©es** : Vid√©os converties
- **Sorties** : Fichiers CSV avec timestamps des sc√®nes
- **Technologies** : TransNetV2 avec PyTorch
- **Configuration** : Fichier `config/step3_transnet.json` pour tuning avanc√©
  - `threshold` : Seuil de d√©tection (d√©faut: 0.5)
  - `window`, `stride`, `padding` : Param√®tres de fen√™tre glissante
  - `device` : Device PyTorch (`cuda`/`cpu`/`auto`)
  - `ffmpeg_threads` : Threads FFmpeg pour d√©codage streaming
  - `mixed_precision` : Activer AMP (Automatic Mixed Precision)
  - `amp_dtype` : Type pour AMP (`float16`/`bfloat16`)
  - `num_workers` : Workers pour parall√©lisation multi-vid√©os (max 1 en CUDA)
  - `torchscript` : Activer compilation TorchScript
  - `warmup` : Warm-up du mod√®le
  - `warmup_batches` : Nombre de batches de warm-up
  - `torchscript_auto_fallback` : Fallback automatique vers Eager si TorchScript √©choue
- **Optimisations v4.1** :
  - Ex√©cution en `torch.inference_mode()` avec AMP optionnelle
  - D√©codage FFmpeg en streaming (fen√™tre glissante avec padding)
  - FPS forc√© √† 25.0 (constante, helper `get_video_fps()`)
  - Parall√©lisation multi-vid√©os born√©e (process pool, limitation 1 worker en CUDA)
  - Warm-up mod√®le et compilation TorchScript optionnelle (wrapper `InferenceWrapper`)
  - Fallback automatique Eager si TorchScript √©choue
  - `cudnn.benchmark=True` sur CUDA pour optimisation kernel
- **Formats de logs support√©s pour progression** :
  - `TOTAL_VIDEOS_TO_PROCESS: N` (avec underscore ou espace)
  - `PROCESSING_VIDEO: <filename>` (nom de fichier seul)
  - `INTERNAL_PROGRESS: N batches - <filename>` (progression simple sans pourcentage)
  - Ligne de succ√®s : `Succ√®s: <filename>.csv cr√©√©`

#### √âtape 4 : Analyse Audio (`run_audio_analysis.py`)
- **Objectif** : Diarisation et analyse des locuteurs
- **Environnement** : `audio_env/` (sp√©cialis√© Pyannote)
- **Entr√©es** : Vid√©os avec audio
- **Sorties** : Fichiers JSON avec segments de parole et locuteurs (`<stem>_audio.json`)
- **Technologies** : Pyannote.audio 3.1 (profil `config/optimal_tv_config.json` charg√© automatiquement) avec fallback Lemonfox
- **Optimisations v4.1** :
  - **Extraction audio** : ffmpeg (subprocess) remplace MoviePy
    - Extraction vers tmpfs (`/dev/shm`) si disponible pour r√©duire latence I/O
    - Fallback vers r√©pertoire temporaire standard
  - **M√©tadonn√©es vid√©o** : ffprobe remplace OpenCV (fallback FPS=25)
  - **√âcriture JSON streaming** : √âvite le stockage complet en m√©moire
    - Mapping segments‚Üíframes sans mat√©rialisation de la liste diarisation
  - **Optimisations PyTorch** :
    - `inference_mode()` et `no_grad()` pour r√©duire overhead
    - Device policy : CUDA prioritaire avec CPU fallback
    - Configurable via env : `AUDIO_DISABLE_GPU`, `AUDIO_CPU_WORKERS`
  - **Nettoyage robuste** : Suppression syst√©matique des r√©pertoires temporaires
  - **Compatibilit√© STEP5** : Sch√©ma de sortie JSON inchang√©
- **Int√©gration Lemonfox (2025-12-17)** :
  - Activation via `STEP4_USE_LEMONFOX=1` avec fallback automatique Pyannote en cas d'√©chec (timeout/erreur API)
  - Hyperparam√®tres configurables via `LEMONFOX_*` (`DEFAULT_LANGUAGE`, `SPEAKER_LABELS`, `SPEECH_GAP_FILL_SEC`, etc.) pour stabiliser `is_speech_present`
  - Wrapper `run_audio_analysis_lemonfox.py` importe `services/lemonfox_audio_service.py` via `importlib` pour √©viter de charger `flask_caching` dans `audio_env`
  - Pyannote applique le preset `config/optimal_tv_config.json` (profil TV). Si le preset √©choue, fallback minimal journalis√© avant de poursuivre
- **Variables d'environnement** :
  - `AUDIO_DISABLE_GPU` : Forcer CPU (`1` = d√©sactiver GPU)
  - `AUDIO_CPU_WORKERS` : Nombre de threads CPU PyTorch
  - `HF_AUTH_TOKEN` : Token Hugging Face pour mod√®les Pyannote
- **Fonctionnalit√©s** :
  - Extraction audio via ffmpeg (remplace MoviePy) vers tmpfs
  - Identification des locuteurs multiples
  - Support GPU/CPU adaptatif avec PyTorch optimizations
  - R√©duction logs (suppression prints dupliqu√©s)

#### √âtape 5 : Suivi Vid√©o (`run_tracking_manager.py`)
- **Objectif** : Suivi et d√©tection d'objets/visages
- **Environnement** : `tracking_env/` (sp√©cialis√© MediaPipe)
- **Entr√©es** : Vid√©os avec analyses sc√®nes/audio
- **Sorties** : Fichiers JSON avec donn√©es de tracking (`<stem>_tracking.json`)
- **Technologies** : MediaPipe avec OpenCV
- **Configuration CPU-only par d√©faut (v4.1)** :
  - Variables d'environnement fix√©es dans `app_new.py` :
    - `TRACKING_DISABLE_GPU=1` : D√©sactive GPU
    - `TRACKING_CPU_WORKERS=15` : Nombre de workers CPU internes
  - Param√®tres CLI support√©s par `run_tracking_manager.py` :
    - `--disable_gpu` : Force d√©sactivation GPU
    - `--cpu_internal_workers N` : Override nombre de workers
  - **Raison** : Meilleures performances globales et stabilit√© sur lots multi-vid√©os
- **Progression UI (corrections v4.1)** :
  - **Backend (`app_new.py`)** :
    - Initialisation correcte du compteur `files_completed` lors du parsing du total
    - Contribution fractionnaire par fichier plafonn√©e √† 0.99 pendant traitement
    - Reset de `progress_current_fractional` apr√®s chaque succ√®s (√©vite report entre fichiers)
    - Parsing des lignes de succ√®s : `[Gestionnaire] Succ√®s pour <filename>`
  - **Frontend (`static/uiUpdater.js`)** :
    - D√©sactivation du fallback ¬´ pourcentage dans le texte ¬ª pour STEP5 (√©vite faux positifs)
    - Garde-fous : cap √† 99% si statut ‚àà {running, starting, initiated}
    - Pas d'affichage 100% tant que statut ‚â† `completed`
    - Gestion sp√©ciale si `progress_current == progress_total` mais statut en cours
- **Restrictions GPU (d√©cision 27/12/2025)** :
  - `STEP5_ENABLE_GPU=1` n'autorise plus que le moteur InsightFace √† utiliser le GPU.
  - MediaPipe Face Landmarker, OpenSeeFace, OpenCV YuNet/PyFeat et EOS sont forc√©s en mode CPU m√™me si le flag GPU est actif.
  - Le gestionnaire cr√©e au plus **un worker GPU s√©quentiel** (pas de parall√©lisation) et bascule automatiquement en CPU si `Config.check_gpu_availability()` √©choue ou si `STEP5_GPU_FALLBACK_AUTO=1`.
  - `process_video_worker_multiprocessing.py` applique un **lazy import MediaPipe** (`_ensure_mediapipe_loaded(required=False)`) pour √©viter de charger TensorFlow quand seuls les moteurs OpenCV/EOS sont utilis√©s.
- **Fonctionnalit√©s** :
  - D√©tection faciale avanc√©e
  - Tracking d'objets avec fallback
  - Analyse de parole enrichie
  - Mode CPU-only par d√©faut avec 15 workers internes
  - D√©tection de parole avanc√©e bas√©e sur l'ouverture de la m√¢choire
  - **Registry object detection MediaPipe** : `workflow_scripts/step5/object_detector_registry.py` centralise les mod√®les fallback (`efficientdet_lite0/1/2`, `ssd_mobilenet_v3`, `yolo11n_onnx`, `nanodet_plus`). Les variables `STEP5_ENABLE_OBJECT_DETECTION`, `STEP5_OBJECT_DETECTOR_MODEL`, `STEP5_OBJECT_DETECTOR_MODEL_PATH` d√©finissent le mod√®le actif. La r√©solution des chemins suit `override_path` > env > `workflow_scripts/step5/models/object_detectors/<backend>/...`. Voir `STEP5_SUIVI_VIDEO.md` pour la table mAP/hardware.

#### √âtape 6 : R√©duction JSON (`json_reducer.py`)
- **Objectif** : Optimisation des fichiers JSON pour After Effects
- **Environnement** : `env/` (environnement principal)
- **Entr√©es** : Fichiers JSON de tracking et d'audio
- **Sorties** : M√™mes fichiers JSON, mais avec une taille r√©duite
- **Fonctionnalit√©s** :
  - Suppression des donn√©es non essentielles (ex: landmarks, blendshapes)
  - Modification des fichiers sur place pour √©conomiser l'espace disque
  - Traitement par lot bas√© sur un mot-cl√©

#### √âtape 7 : Finalisation (`finalize_and_copy.py`)
- **Objectif** : Consolidation et archivage des r√©sultats
- **Environnement** : `env/` (environnement principal)
- **Entr√©es** : Tous les fichiers de m√©tadonn√©es g√©n√©r√©s et r√©duits
- **Sorties** : Archive finale organis√©e
- **Fonctionnalit√©s** :
  - Validation de l'int√©grit√© des donn√©es
  - Organisation hi√©rarchique des r√©sultats
  - Nettoyage des fichiers temporaires

---

## Architecture Backend

### Principe Fondamental : Architecture Orient√©e Services

Le backend suit une architecture modulaire stricte bas√©e sur 5 services centralis√©s et des routes organis√©es en Blueprints Flask.

### Les 5 Services Centralis√©s

#### 1. WorkflowState (`services/workflow_state.py`) - Source de V√©rit√© Unique

**Responsabilit√©** : G√®re l'√©tat global du workflow de mani√®re thread-safe.

**Caract√©ristiques cl√©s** :
- Singleton accessible via `get_workflow_state()`
- G√®re l'√©tat des √©tapes (STEP1 √† STEP7)
- G√®re les verrous et la synchronisation
- Fournit des m√©thodes pour mettre √† jour et interroger l'√©tat
- Interface coh√©rente pour l'acc√®s aux logs et m√©triques

**Migration en cours** :
- `app_new.py` utilise pleinement `WorkflowState`
- `WorkflowService` s‚Äôappuie sur `WorkflowState` pour la lecture/√©criture de l‚Äô√©tat, et d√©pend de `app_new` uniquement pour d√©clencher l‚Äôex√©cution (threads/subprocess)

#### 2. WorkflowService (`services/workflow_service.py`) - ‚úÖ Finalis√©
**Responsabilit√©** : Point d‚Äôentr√©e unique pour l‚Äôex√©cution des √©tapes, des s√©quences et des logs sp√©cifiques (avec pr√©paration STEP5, gestion des fichiers temporaires, etc.).

```python
from services.workflow_service import WorkflowService

# Ex√©cution d'une √©tape
result = WorkflowService.run_step("STEP1")

# S√©quence personnalis√©e
sequence_result = WorkflowService.run_custom_sequence(["STEP1", "STEP2"])

# R√©cup√©ration d'un log sp√©cifique
log_file = WorkflowService.get_step_log_file("STEP1", 0)

```

**Fonctionnalit√©s cl√©s (v4.2)** :
- **Thin Controllers** : toutes les routes (`routes/api_routes.py`, `routes/workflow_routes.py`) d√©l√®guent la logique m√©tier au service (z√©ro duplication de `COMMANDS_CONFIG`).
- **Logs unifi√©s** : `get_step_log_file()` s‚Äôappuie sur `WorkflowCommandsConfig` pour les chemins et patterns, garantissant l‚Äôalignement avec les commandes ex√©cut√©es.
- **Gestion d‚Äô√©tat centralis√©e** : chaque op√©ration lit/√©crit exclusivement via `WorkflowState` (statuts, dur√©es, logs, process, s√©quences).
- **Instrumentation native** : tous les endpoints li√©s (`/api/run_step/*`, `/api/get_specific_log/*`) sont d√©cor√©s avec `@measure_api`.

**B√©n√©fices obtenus** :
- R√©duction de 63‚ÄØ% de la complexit√© de `execute_csv_download_worker()` (230 ‚Üí 85 lignes) gr√¢ce aux helpers WorkflowService.
- Suppression compl√®te des reliques `PROCESS_INFO`, `COMMANDS_CONFIG`, `sequence_lock`, `LAST_SEQUENCE_OUTCOME`.
- Tests unitaires et d‚Äôint√©gration couvrant les routes, la r√©cup√©ration de logs, l‚Äôex√©cution d‚Äô√©tapes/s√©quences et l‚Äôadaptive chunking STEP5.
- Architecture maintenable et extensible : service stateless, √©tat unique (`WorkflowState`), configuration unique (`WorkflowCommandsConfig`).

> ‚ÑπÔ∏è **Note (2026-01-18)** ‚Äî La configuration dynamique des chunks STEP5 via `/api/step5/chunk_bounds` a √©t√© retir√©e. Les paragraphes ci-dessus d√©crivent l‚Äô√©tat actuel (chunking adaptatif interne uniquement). Voir `memory-bank/decisionLog.md` pour la d√©cision compl√®te.

**Statut** : ‚úÖ Migration finalis√©e (janvier‚ÄØ2026). Voir `docs/workflow/MIGRATION_STATUS.md` pour l‚Äôhistorique d√©taill√©.

#### 3. MonitoringService (`services/monitoring_service.py`)
**Responsabilit√©** : Surveillance des ressources syst√®me et diagnostics

```python
from services.monitoring_service import MonitoringService

# Statut syst√®me complet
status = MonitoringService.get_system_status()

# Informations de diagnostics
env_info = MonitoringService.get_environment_info()

# M√©triques sp√©cifiques
cpu_usage = MonitoringService.get_cpu_usage()
memory_info = MonitoringService.get_memory_usage()
gpu_info = MonitoringService.get_gpu_usage()  # Support NVIDIA
disk_usage = MonitoringService.get_disk_usage()
```

**Fonctionnalit√©s** :
- Monitoring CPU, RAM, GPU (NVIDIA), disque
- Informations de diagnostics syst√®me (versions Python/FFmpeg, disponibilit√© GPU, flags de configuration filtr√©s)
- V√©rifications de sant√© syst√®me
- Alertes de temp√©rature et utilisation
- M√©triques en temps r√©el

#### 4. CacheService (`services/cache_service.py`)
**Responsabilit√©** : Mise en cache intelligente avec TTL

```python
from services.cache_service import CacheService

# Configuration frontend mise en cache
frontend_config = CacheService.get_cached_frontend_config()

# Contenu de logs sp√©cifiques (TTL court)
log_content = CacheService.get_cached_log_content("STEP4", 0)

# Statistiques d√©taill√©es
cache_stats = CacheService.get_cache_stats()
print(f"Taux de r√©ussite cache: {cache_stats['hit_rate']:.1%}")
```

**Fonctionnalit√©s** :
- Cache avec expiration automatique (TTL)
- Invalidation par motifs
- Statistiques de performance
- Gestion m√©moire optimis√©e

#### 5. PerformanceService (`services/performance_service.py`)
**Responsabilit√©** : Suivi des performances et profilage

```python
from services.performance_service import PerformanceService

# Suivi des performances API
PerformanceService.track_api_call("/api/system_monitor", 150)

# Suivi des performances d'√©tapes
PerformanceService.track_step_performance("STEP1", 2500)

# M√©triques compl√®tes
metrics = PerformanceService.get_performance_summary()
```

**M√©triques suivies** :
- Temps de r√©ponse des API
- Dur√©e d'ex√©cution des √©tapes
- Utilisation des ressources
- Tendances de performance

#### 6. CSVService (`services/csv_service.py`)
**Responsabilit√©** : Interface vers le monitoring Webhook des t√©l√©chargements (source unique) + persistance SQLite de l‚Äôhistorique

```python
from services.csv_service import CSVService

# Statut du monitoring Webhook
monitor_status = CSVService.get_monitor_status()
print(monitor_status['data_source'])  # "webhook"
print(monitor_status['webhook'])        # statut du service Webhook

# T√©l√©chargements actifs et r√©cents
download_status = CSVService.get_csv_downloads_status()
active_downloads = download_status['active_downloads']
recent_statuses = download_status['recent_statuses']

# Historique des t√©l√©chargements
history = CSVService.get_download_history()
is_downloaded = CSVService.is_url_downloaded(url)
```

**Fonctionnalit√©s principales** :
- **Interface Webhook** : Communication avec le service Webhook pour la r√©cup√©ration des donn√©es (Dropbox direct + proxys R2 uniquement)
- **Historique SQLite** : Persistance multi-process via `download_history.sqlite3` + `DownloadHistoryRepository` (WAL, partage de permissions, script `scripts/migrate_download_history_to_sqlite.py` pour l‚Äôimport legacy)
- **Normalisation URLs** : √âlimination des doublons, nettoyage double-encodage
- **WorkflowState** : Int√©gration compl√®te pour l‚Äô√©tat des t√©l√©chargements et la d√©duplication intra-iteration

**Architecture simplifi√©e** :
- Source de donn√©es unique : Webhook JSON (`WEBHOOK_JSON_URL`, `WEBHOOK_MONITOR_INTERVAL`, `WEBHOOK_CACHE_TTL`, `WEBHOOK_TIMEOUT`)
- Plus aucun fallback CSV/MySQL/Airtable dans le code actif (les documents legacy sont archiv√©s dans `docs/workflow/legacy/`)
- Politique ‚ÄúDropbox-only‚Äù pour l‚Äôauto-download, liens externes ignor√©s ou ouverts manuellement par le frontend


#### 7. ResultsArchiver (`services/results_archiver.py`)
**Responsabilit√©** : Persistance permanente des analyses au-del√† du cycle de vie des projets

```python
from services.results_archiver import ResultsArchiver

# Calcul du hash SHA-256 de la vid√©o
video_hash = ResultsArchiver.compute_video_hash(video_path)

# Archivage automatique des analyses
archive_dir = ResultsArchiver.archive_analysis_files(
    project_name="projet_camille_001",
    video_path=video_path,
    scenes_file=scenes_csv_path,
    audio_file=audio_json_path,
    tracking_file=tracking_json_path
)

# Chargement avec fallback automatique
archived = ResultsArchiver.load_archived_analysis(project_name, video_path)
if archived and archived.get('scenes_csv'):
    scenes_csv = archived['scenes_csv']

# V√©rification de disponibilit√©
has_scenes, has_audio, has_tracking = ResultsArchiver.project_has_analysis(project_name)
```

**Fonctionnalit√©s** :
- **Indexation par hash SHA-256** : Identification unique bas√©e sur le contenu vid√©o
- **Structure d'archives** : `archives/{project_name}/{video_hash}/`
- **Fallback automatique** : Recherche par hash puis par nom de fichier
- **Protection des donn√©es** : Le r√©pertoire `ARCHIVES_DIR` n'est jamais supprim√©
- **M√©tadonn√©es horodat√©es** : Timestamps UTC pour tra√ßabilit√©
- **Int√©gration workflow** : Archivage automatique aux √âtapes 3, 4, 5

**Documentation compl√®te** : [RESULTS_ARCHIVER_SERVICE.md](RESULTS_ARCHIVER_SERVICE.md)

#### 9. VisualizationService (`services/visualization_service.py`)

#### 10. WorkflowCommandsConfig (`config/workflow_commands.py`)
**Responsabilit√©** : Source unique de configuration pour les 7 √©tapes (commandes, CWD, logs sp√©cifiques, patterns de progression, messages UI).

```python
from config.workflow_commands import WorkflowCommandsConfig

cfg = WorkflowCommandsConfig(base_path=config.BASE_PATH_SCRIPTS)

# Obtenir la commande et le r√©pertoire de travail d'une √©tape
cmd = cfg.get_step_command('STEP4')
cwd = cfg.get_step_cwd('STEP4')

# Mettre √† jour dynamiquement le token HF pour STEP4
cfg.update_hf_token(os.getenv('HUGGINGFACE_HUB_TOKEN', ''))
```

**Points cl√©s** :
- Cr√©e les r√©pertoires de logs `logs/step{N}` si absents.
- Expose `get_all_step_keys()`, `get_step_config()`, `get_step_display_name()`.
- Centralise les regex de parsing de progression pour un comportement uniforme.
**Responsabilit√©** : Agr√©gation et traitement des donn√©es pour rapports

```python
from services.visualization_service import VisualizationService

# Liste des projets disponibles (fusion projets actifs + archives)
projects = VisualizationService.get_available_projects()
for project in projects["projects"]:
    print(f"{project['name']}: {project['video_count']} vid√©os")
    print(f"  Source: {project['source']}")  # "projects" ou "archives"
    print(f"  Analyses: sc√®nes={project['has_scenes']}, audio={project['has_audio']}")


**Fonctionnalit√©s** :
- **Fusion projets/archives** : Combine les projets actifs (`projets_extraits/`) et archiv√©s (`archives/`)
- **Fallback automatique** : Si analyses absentes du projet, charge depuis archives
- **Provenance des donn√©es** : Indique l'origine via `archive_probe_source` (`project` ou `archives`)
- **Support multi-formats** : CSV sc√®nes, JSON audio, JSON tracking
- **Horodatage** : Date d'archivage pour donn√©es archiv√©es

#### 11. LemonfoxAudioService (`services/lemonfox_audio_service.py`)
**Responsabilit√©** : Service d'analyse audio via API Lemonfox (alternative √† Pyannote)

```python
from services.lemonfox_audio_service import LemonfoxAudioService

# Traitement vid√©o avec Lemonfox
result = LemonfoxAudioService.process_video_with_lemonfox(
    project_name="mon_projet",
    video_name="videos/ma_video.mp4",
    language="fr",
    speaker_labels=True,
    min_speakers=1,
    max_speakers=4
)

if result.success:
    print(f"Analyse r√©ussie : {result.output_path}")
    print(f"Frames trait√©es : {result.total_frames}")
else:
    print(f"Erreur : {result.error}")
```

**Fonctionnalit√©s principales** :
- **API Lemonfox** : Communication avec le service de speech-to-text cloud
- **Conversion format** : Transformation des donn√©es Lemonfox vers format STEP4
- **Smoothing timeline** : Post-traitement pour stabiliser la d√©tection de parole
- **Fallback automatique** : Bascule vers Pyannote en cas d'√©chec
- **Configuration flexible** : Param√®tres ajustables via variables d'environnement

**Configuration** :
- `STEP4_USE_LEMONFOX=1` pour activer
- `LEMONFOX_API_KEY` obligatoire si activ√©
- Variables `LEMONFOX_*` pour param√®tres avanc√©s

#### 12. WebhookService (`services/webhook_service.py`)
**Responsabilit√©** : Source de donn√©es JSON externe pour monitoring des t√©l√©chargements

```python
from services.webhook_service import fetch_records, get_service_status

# R√©cup√©ration des enregistrements
records = fetch_records()

# Statut du service
status = get_service_status()
```

**Fonctionnalit√©s** :
- **Source JSON externe** : R√©cup√©ration de donn√©es depuis endpoint configurable
- **Cache TTL** : Mise en cache avec expiration configurable
- **Validation robuste** : Parsing et validation des donn√©es JSON
- **Classification d'URLs** : D√©tection automatique du type (dropbox, proxy PHP)
- **Retry automatique** : Gestion d'erreurs avec backoff exponentiel

**Documentation compl√®te** : [WEBHOOK_INTEGRATION.md](WEBHOOK_INTEGRATION.md)

### Organisation des Routes (Blueprints Flask)

#### Blueprint API (`routes/api_routes.py`)
**Endpoints syst√®me et administration** (12 routes) :
- `/api/system_monitor` : Statut syst√®me complet
- `/api/system/diagnostics` : Informations syst√®me d√©taill√©es
- `/api/cache/*` : Gestion du cache
- `/api/performance/*` : M√©triques de performance
- `/api/csv_monitor_status` : Statut du monitoring CSV
- `/api/csv_downloads_status` : Statut des t√©l√©chargements CSV

#### Blueprint Workflow (`routes/workflow_routes.py`)
**Endpoints d'ex√©cution workflow** (18 routes) :
- `/run/<step_key>` : Ex√©cution d'√©tape
- `/run_custom_sequence` : S√©quences personnalis√©es
- `/status/<step_key>` : Statut d'√©tape
- `/get_sequence_status` : √âtat des s√©quences
- `/get_specific_log/<step_key>/<int:log_index>` : Logs d√©taill√©s
- `/cancel/<step_key>` : Annulation d'√©tape

### Gestion d'√âtat Centralis√©e

L'√©tat de l'application est g√©r√© via le service `WorkflowState` (thread-safe) :

```python
from services.workflow_state import get_workflow_state

ws = get_workflow_state()

# Initialiser les √©tapes connues (au d√©marrage)
ws.initialize_all_steps(['STEP1','STEP2','STEP3','STEP4','STEP5','STEP6','STEP7'])

# Mettre √† jour le statut/progression d'une √©tape
ws.update_step_status('STEP3', 'running')
ws.update_step_progress('STEP3', current=2, total=5, text='video2.mp4')

# D√©marrer/terminer une s√©quence
ws.start_sequence('Full')
ws.complete_sequence(success=True, message='OK', sequence_type='Full')

# Lecture d'√©tat (copies thread-safe)
step_info = ws.get_step_info('STEP3')
all_info = ws.get_all_steps_info()
```

**Principe** : Les routes restent des contr√¥leurs minces et d√©l√®guent aux services; l‚Äô√©tat est lu/√©crit exclusivement via `WorkflowState`.

---

## Architecture Frontend

### Principe Fondamental : √âtat Centralis√© et Optimisations de Performance

Le frontend suit une architecture bas√©e sur un √©tat centralis√© immutable avec des optimisations de performance avanc√©es.

### Gestion d'√âtat Centralis√©e : AppState

#### AppState (`static/state/AppState.js`)
**Responsabilit√©** : Gestion immutable de l'√©tat de l'application (remplace compl√®tement `state.js` depuis le 21/01/2026).

```javascript
import { appState } from './state/AppState.js';

// Lecture immutable
const {
    activeStepKeyForLogsPanel,
    stepTimers,
    performanceMetrics
} = appState.getState();

// Mise √† jour (immutabilit√© garantie via merge profond interne)
appState.setState({
    stepTimers: {
        ...stepTimers,
        STEP3: { startTime: Date.now(), elapsedMs: 0 }
    }
}, 'step_timer_start');

// Abonnement cibl√©
const unsubscribe = appState.subscribe((newState, prevState) => {
    if (newState.activeStepKeyForLogsPanel !== prevState.activeStepKeyForLogsPanel) {
        updateLogsPanel(newState.activeStepKeyForLogsPanel);
    }
});
```

**Structure actuelle de l'√©tat**

```javascript
{
  pollingIntervals: {},
  activeStepKeyForLogsPanel: null,
  isAnySequenceRunning: false,
  focusedElementBeforePopup: null,
  ui: {
    compactMode: false,
    localDownloadsVisible: true
  },
  stepTimers: {},
  selectedStepsOrder: [],
  processInfo: {},
  performanceMetrics: {
    apiResponseTimes: [],
    errorCounts: {},
    lastUpdate: null
  },
  cacheStats: {
    hits: 0,
    misses: 0,
    hitRate: 0
  }
}
```

**Fonctionnalit√©s** :
- **√âtat immutable** : Pr√©vient les mutations accidentelles (copie profonde via `_mergeDeep`).
- **Notifications de changement** : Abonnements globaux (`subscribe`) ou cibl√©s (`subscribeToProperty`).
- **Mises √† jour group√©es** : `batchUpdate()` combine plusieurs mutations et ne notifie qu'une seule fois.
- **Hooks UI** : Gestion int√©gr√©e des timers d'√©tapes, du panneau de logs connect√© et des m√©triques de performance.
- **Compatibilit√© legacy** : Les anciens exports (`state.js`) ont √©t√© supprim√©s; tout nouveau module doit d√©pendre d‚Äô`appState`.
- **Optimisation planifi√©e** : L‚Äôaudit frontend recommande de remplacer `_deepClone` par `structuredClone()` et d‚Äô√©viter les comparaisons `JSON.stringify` pour `_stateChanged` (TODO suivi dans l‚Äôaudit).

#### Structure de l'√âtat

> **Note** : L‚Äôancienne structure `stepStatuses/systemStatus/uiState` d√©crite lors de la phase `state.js` n‚Äôest plus utilis√©e. Toute logique d√©pendante doit migrer vers les cl√©s list√©es ci-dessus ou introduire explicitement les nouvelles propri√©t√©s n√©cessaires dans `AppState`.

### Optimisations de Performance

#### DOMBatcher (`static/utils/DOMBatcher.js`)
**Responsabilit√©** : Optimisation des mises √† jour DOM group√©es

```javascript
import { domBatcher } from './utils/DOMBatcher.js';

// Mise √† jour group√©e du DOM
domBatcher.batchUpdate(() => {
    updateStepProgress('STEP1', 50);
    updateStepStatus('STEP1', 'running');
    updateSystemMetrics(newMetrics);
});

// Les mises √† jour sont automatiquement group√©es et optimis√©es
```

**Fonctionnalit√©s** :
- **Groupement automatique** : Combine plusieurs mises √† jour DOM
- **RequestAnimationFrame** : Synchronisation avec le cycle de rendu
- **Pr√©vention des reflows** : Minimise les recalculs de layout
- **Mesure de performance** : M√©triques de temps d'ex√©cution

#### Logs Panel ‚Äî Theme & Auto-scroll

- **Mode cin√©matique retir√©** : depuis le 2026‚Äë01‚Äë21, il n‚Äôexiste plus de module `static/cinematicLogMode.js` ni de toggle associ√©. Tous les panneaux utilisent le th√®me Timeline Connect√©e (CSS `static/css/components/logs.css`).
- **Animations & accessibilit√©** : les effets respectent `prefers-reduced-motion` et n‚Äôinjectent plus d‚Äôattributs `data-cinematic-mode`.
- **Auto-scroll structurel** : `scrollManager` et `sequenceManager` g√®rent automatiquement le centrage vertical (spacer d√©di√©, throttling 700‚ÄØms, compensation topbar) sans r√©glage utilisateur.

#### Cache-busting CSS (v4.1)

- Pour garantir le rechargement des styles apr√®s une mise √† jour, toutes les feuilles de style dans `templates/index_new.html` utilisent un param√®tre de version: `?v={{ cache_buster }}`.
- Cette pratique √©vite les caches agressifs du navigateur lors des it√©rations rapides UI/UX.

#### S√©curit√© XSS et Instrumentation API (rappels v4.1)

- Toute insertion de texte dynamique dans le DOM doit √™tre √©chapp√©e via `DOMUpdateUtils.escapeHtml()` (voir `static/utils/DOMBatcher.js`).
- Tous les endpoints Flask doivent √™tre instrument√©s via un d√©corateur standard (ex: `measure_api()` dans `routes/api_routes.py`) qui enregistre les timings via `PerformanceService`. Voir [API_INSTRUMENTATION.md](API_INSTRUMENTATION.md).

### Composants de Gestion

#### PollingManager (`static/utils/PollingManager.js`)
**Responsabilit√©** : Gestion centralis√©e du polling avec nettoyage automatique

```javascript
// D√©marrage du polling g√©r√©
pollingManager.startPolling('stepStatus', async () => {
    const status = await fetchStepStatus();
    appState.setState({ stepStatuses: status });
}, 1000, { immediate: true });

// Nettoyage automatique au d√©chargement de la page
// (g√©r√© automatiquement par PollingManager)
```

**Fonctionnalit√©s** :
- **Gestion des ressources** : Nettoyage automatique des timers
- **Backoff adaptatif** : Pause temporaire si le callback retourne un d√©lai (ms), reprise automatique
- **Gestion d'erreurs** : Arr√™t automatique apr√®s erreurs r√©p√©t√©es
- **Compatibilit√© mobile** : Pause sur tab inactive
- **Mesure de performance** : Suivi des ressources utilis√©es de polling

#### ErrorHandler (`static/utils/ErrorHandler.js`)
**Responsabilit√©** : Gestion centralis√©e des erreurs

Gestion d'√âtat

#### Workflow d'Ex√©cution d'√âtape

1. **D√©clenchement** : Utilisateur clique sur "Ex√©cuter"
2. **Validation** : V√©rification des pr√©requis c√¥t√© frontend
3. **Appel API** : `POST /run/<step_key>`
4. **R√©ponse imm√©diate** : Statut "initiated" retourn√©
5. **Polling** : Surveillance continue du statut
6. **Mise √† jour UI** : Progression en temps r√©el
7. **Finalisation** : Notification de fin d'ex√©cution

#### Gestion des S√©quences

```javascript
// Ex√©cution de s√©quence personnalis√©e
const executeSequence = async (steps) => {
    try {
        // D√©marrage de la s√©quence
        const result = await apiService.runCustomSequence(steps);

        // Monitoring de la s√©quence
        pollingManager.startPolling('sequenceStatus',
            updateSequenceStatus, 500);
    } catch (error) {
        errorHandler.handleSequenceError(error);
    }
};
```

### Communication Frontend/Backend

#### API Service (`static/apiService.js`)
**Responsabilit√©** : Interface centralis√©e pour les appels API

```javascript
import { apiService } from './apiService.js';

// Ex√©cution d'√©tape
const result = await apiService.runStep('STEP1');

// R√©cup√©ration du statut
const status = await apiService.getStepStatus('STEP1');

// Monitoring syst√®me
const systemStatus = await apiService.getSystemStatus();
```

### Sources de T√©l√©chargement (Dropbox uniquement)

#### Politique Dropbox-only
- Seules les URLs Dropbox directes et proxys PHP d√©clenchent un t√©l√©chargement automatique.
- Les autres sources (FromSmash, SwissTransfer, etc.) sont ignor√©es ou n√©cessitent une ouverture manuelle.
- Raison: s√©curit√© et compatibilit√© UX.

#### Flux de Donn√©es Temps R√©el

```mermaid
sequenceDiagram
    participant F as Frontend
    participant P as PollingManager
    participant A as API Service
    participant B as Backend Services
    participant S as AppState

    F->>P: D√©marrer polling
    loop Toutes les 1000ms
        P->>A: Requ√™te statut
        A->>B: Appel service
        B-->>A: Donn√©es
        A-->>P: R√©ponse
        P->>S: Mise √† jour √©tat
        S->>F: Notification changement
        F->>F: Mise √† jour UI
    end
```

#### Gestion des Erreurs Int√©gr√©e

```javascript
// Gestion automatique des erreurs avec retry
const fetchWithRetry = async (operation, ...args) => {
    try {
        const result = await operation(...args);
        errorHandler.clearErrors(operation.name);
        return result;
    } catch (error) {
        await errorHandler.handlePollingError(operation.name, error);

        // Retry automatique pour certaines erreurs
        if (error.status === 503) {
            return retryWithBackoff(operation, args);
        }
        throw error;
    }
};
```

### Synchronisation d'√âtat

#### Workflow d'Ex√©cution d'√âtape

1. **D√©clenchement** : Utilisateur clique sur "Ex√©cuter"
2. **Validation** : V√©rification des pr√©requis c√¥t√© frontend
3. **Appel API** : `POST /run/<step_key>`
4. **R√©ponse imm√©diate** : Statut "initiated" retourn√©
5. **Polling** : Surveillance continue du statut
6. **Mise √† jour UI** : Progression en temps r√©el
7. **Finalisation** : Notification de fin d'ex√©cution

#### Gestion des S√©quences

```javascript
// Ex√©cution de s√©quence personnalis√©e
const executeSequence = async (steps) => {
    try {
        // D√©marrage de la s√©quence
        const result = await apiService.runCustomSequence(steps);

        // Monitoring de la s√©quence
        pollingManager.startPolling('sequenceStatus',
            updateSequenceStatus, 500);
    } catch (error) {
        errorHandler.handleSequenceError(error);
    }
};
```

---

## Points d'Int√©gration

### Communication Frontend/Backend

#### API Service (`static/apiService.js`)
**Responsabilit√©** : Interface centralis√©e pour les appels API

```javascript
import { apiService } from './apiService.js';

// Ex√©cution d'√©tape
const result = await apiService.runStep('STEP1');

// R√©cup√©ration du statut
const status = await apiService.getStepStatus('STEP1');

// Monitoring syst√®me
const systemStatus = await apiService.getSystemStatus();
```

### Sources de T√©l√©chargement (Dropbox uniquement)

#### Politique Dropbox-only
- Seules les URLs Dropbox directes et proxys PHP d√©clenchent un t√©l√©chargement automatique.
- Les autres sources (FromSmash, SwissTransfer, etc.) sont ignor√©es ou n√©cessitent une ouverture manuelle.
- Raison: s√©curit√© et compatibilit√© UX.

#### Flux de Donn√©es Temps R√©el

```mermaid
sequenceDiagram
    participant F as Frontend
    participant P as PollingManager
    participant A as API Service
    participant B as Backend Services
    participant S as AppState

    F->>P: D√©marrer polling
    loop Toutes les 1000ms
        P->>A: Requ√™te statut
        A->>B: Appel service
        B-->>A: Donn√©es
        A-->>P: R√©ponse
        P->>S: Mise √† jour √©tat
        S->>F: Notification changement
        F->>F: Mise √† jour UI
    end
```

#### Gestion des Erreurs Int√©gr√©e

```javascript
// Gestion automatique des erreurs avec retry
const fetchWithRetry = async (operation, ...args) => {
    try {
        const result = await operation(...args);
        errorHandler.clearErrors(operation.name);
        return result;
    } catch (error) {
        await errorHandler.handlePollingError(operation.name, error);

        // Retry automatique pour certaines erreurs
        if (error.status === 503) {
            return retryWithBackoff(operation, args);
        }
        throw error;
    }
};
```

### Synchronisation d'√âtat

#### Workflow d'Ex√©cution d'√âtape

1. **D√©clenchement** : Utilisateur clique sur "Ex√©cuter"
2. **Validation** : V√©rification des pr√©requis c√¥t√© frontend
3. **Appel API** : `POST /run/<step_key>`
4. **R√©ponse imm√©diate** : Statut "initiated" retourn√©
5. **Polling** : Surveillance continue du statut
6. **Mise √† jour UI** : Progression en temps r√©el
7. **Finalisation** : Notification de fin d'ex√©cution

#### Gestion des S√©quences

```javascript
// Ex√©cution de s√©quence personnalis√©e
const executeSequence = async (steps) => {
    try {
        // D√©marrage de la s√©quence
        const result = await apiService.runCustomSequence(steps);

        // Monitoring de la s√©quence
        pollingManager.startPolling('sequenceStatus',
            updateSequenceStatus, 500);
    } catch (error) {
        errorHandler.handleSequenceError(error);
    }
};
```

---

## Structure des Fichiers

### Organisation G√©n√©rale

```workflow_mediapipe/
‚îú‚îÄ‚îÄ app_new.py                 # Application Flask principale
‚îú‚îÄ‚îÄ config/                    # Configuration centralis√©e
‚îÇ   ‚îú‚îÄ‚îÄ settings.py           # Param√®tres g√©n√©raux
‚îÇ   ‚îî‚îÄ‚îÄ security.py           # Configuration s√©curit√©
‚îú‚îÄ‚îÄ routes/                    # Blueprints Flask
‚îÇ   ‚îú‚îÄ‚îÄ api_routes.py         # Endpoints syst√®me (12 routes)
‚îÇ   ‚îî‚îÄ‚îÄ workflow_routes.py    # Endpoints workflow (18 routes)
‚îú‚îÄ‚îÄ services/                  # Logique m√©tier (5 services)
‚îÇ   ‚îú‚îÄ‚îÄ workflow_service.py   # Gestion workflow
‚îÇ   ‚îú‚îÄ‚îÄ monitoring_service.py # Monitoring syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ cache_service.py      # Cache intelligent
‚îÇ   ‚îú‚îÄ‚îÄ performance_service.py # M√©triques performance
‚îÇ   ‚îî‚îÄ‚îÄ csv_service.py        # Monitoring t√©l√©chargements (Airtable/CSV)
‚îú‚îÄ‚îÄ workflow_scripts/          # Scripts de traitement
‚îÇ   ‚îú‚îÄ‚îÄ step1/               # Extraction archives
‚îÇ   ‚îú‚îÄ‚îÄ step2/               # Conversion vid√©o
‚îÇ   ‚îú‚îÄ‚îÄ step3/               # D√©tection sc√®nes
‚îÇ   ‚îú‚îÄ‚îÄ step4/               # Analyse audio
‚îÇ   ‚îú‚îÄ‚îÄ step5/               # Suivi vid√©o
‚îÇ   ‚îú‚îÄ‚îÄ step6/               # R√©duction JSON (√âtape 6)
‚îÇ   ‚îî‚îÄ‚îÄ step7/               # Finalisation (√âtape 7)
‚îú‚îÄ‚îÄ static/                   # Frontend JavaScript
‚îÇ   ‚îú‚îÄ‚îÄ main.js              # Point d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ state/               # Gestion d'√©tat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AppState.js      # √âtat centralis√©
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Utilitaires performance
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DOMBatcher.js    # Optimisation DOM
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DOMBatcher.js # Mises √† jour DOM group√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PollingManager.js # Gestion polling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ErrorHandler.js  # Gestion erreurs
‚îÇ   ‚îú‚îÄ‚îÄ css/                 # Styles modulaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.css    # Variables CSS
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/      # Styles par composant
‚îÇ   ‚îî‚îÄ‚îÄ [autres modules JS]  # Modules sp√©cialis√©s
‚îú‚îÄ‚îÄ utils/                   # Utilitaires backend
‚îÇ   ‚îî‚îÄ‚îÄ resource_manager.py  # Gestion ressources
‚îú‚îÄ‚îÄ tests/                   # Tests complets
‚îÇ   ‚îú‚îÄ‚îÄ unit/               # Tests unitaires
‚îÇ   ‚îú‚îÄ‚îÄ integration/        # Tests d'int√©gration
‚îÇ   ‚îú‚îÄ‚îÄ frontend/           # Tests frontend
‚îÇ   ‚îî‚îÄ‚îÄ validation/         # Scripts de validation
‚îú‚îÄ‚îÄ templates/              # Templates HTML
‚îÇ   ‚îî‚îÄ‚îÄ index_new.html      # Interface principale
‚îú‚îÄ‚îÄ logs/                   # Journaux syst√®me
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îî‚îÄ‚îÄ [environnements virtuels] # env/, transnet_env/, etc.
```

### Responsabilit√©s par R√©pertoire

#### `/services/` - Logique M√©tier
- **R√®gle** : TOUTE la logique m√©tier doit √™tre dans les services
- **Interdiction** : Logique m√©tier dans les routes (contr√¥leurs l√©gers uniquement)
- **Pattern** : M√©thodes statiques, acc√®s thread-safe √† l'√©tat global

#### `/routes/` - Contr√¥leurs L√©gers
- **Responsabilit√©** : Validation, appel de services, formatage de r√©ponse
- **Pattern** :
  1. Validation des param√®tres
  2. Appel du service appropri√©
  3. Formatage de la r√©ponse JSON

#### `/static/` - Frontend Modulaire
- **√âtat** : Centralis√© dans `AppState.js`
- **Performance** : Optimisations obligatoires via `DOMBatcher` et `PerformanceOptimizer`
- **Acc√®s DOM** : Lazy loading, validation d'existence

#### `/workflow_scripts/` - Scripts de Traitement
- **Isolation** : Chaque √©tape dans son environnement virtuel
- **Communication** : Via logs structur√©s et fichiers de sortie
- **Pattern** : Logging standardis√©, gestion d'erreurs robuste

---

## Configuration et S√©curit√©

### Syst√®me de Configuration Centralis√©

#### Configuration Principale (`config/settings.py`)

```python
from config.settings import config

# Acc√®s aux param√®tres
base_path = config.BASE_PATH_SCRIPTS
flask_port = config.FLASK_PORT
debug_mode = config.DEBUG

# Validation automatique
config.validate()  # L√®ve une exception si configuration invalide
```

**Variables d'environnement support√©es** :
```bash
# .env - Configuration principale
FLASK_SECRET_KEY=your-secret-key-here
INTERNAL_WORKER_COMMS_TOKEN=your-secure-token-here
RENDER_REGISTER_TOKEN=your-render-token-here
FLASK_PORT=5000
DEBUG=false

# Int√©gration Airtable (d√©pr√©ci√© - plus utilis√©)
# USE_AIRTABLE=true
# AIRTABLE_ACCESS_TOKEN=your-pat-token
# AIRTABLE_BASE_NAME="Logs T√©l√©chargements"
# AIRTABLE_TABLE_NAME="Table 1"
# AIRTABLE_MONITOR_INTERVAL=15

# Monitoring Webhook (source unique de donn√©es)
WEBHOOK_JSON_URL=https://your-webhook-endpoint.com/data
WEBHOOK_MONITOR_INTERVAL=15
WEBHOOK_CACHE_TTL=60
WEBHOOK_TIMEOUT=10

# Configuration Lemonfox (optionnel - STEP4)
STEP4_USE_LEMONFOX=0
LEMONFOX_API_KEY=your-lemonfox-api-key
LEMONFOX_TIMEOUT_SEC=300
LEMONFOX_EU_DEFAULT=0
```

#### Configuration de S√©curit√© (`config/security.py`)

```python
from config.security import require_internal_worker_token, SecurityConfig

# Protection des endpoints
@app.route('/api/secure-endpoint')
@require_internal_worker_token
def secure_endpoint():
    return jsonify({"status": "authenticated"})

# Configuration s√©curis√©e
security_config = SecurityConfig()
token = security_config.INTERNAL_WORKER_TOKEN
```

### D√©corateurs de S√©curit√©

#### Protection des Endpoints Internes

```python
@require_internal_worker_token
def internal_api_endpoint():
    """Endpoint prot√©g√© pour les workers internes."""
    pass
```

**Fonctionnement** :
1. V√©rification du header `X-Internal-Worker-Token`
2. Comparaison avec le token configur√©
3. Rejet avec 401 si token invalide/absent

#### Validation des Param√®tres

```python
def validate_step_key(step_key):
    """Validation s√©curis√©e des cl√©s d'√©tape."""
    if not step_key or step_key not in COMMANDS_CONFIG:
        raise ValueError("Cl√© d'√©tape invalide")
    return step_key
```

### Gestion des Secrets

#### Principe Z√©ro Secret dans le Code
- **Interdiction** : Aucun token, cl√© ou mot de passe en dur
- **M√©thode** : Variables d'environnement uniquement
- **Validation** : V√©rification au d√©marrage de l'application

#### Exemple de Configuration S√©curis√©e

```python
# ‚ùå INTERDIT
API_KEY = "sk-1234567890abcdef"

# ‚úÖ CORRECT
import os
API_KEY = os.getenv('API_KEY')
if not API_KEY:
    raise ValueError("API_KEY environment variable required")
```

---

## Environnements Virtuels

### Architecture Multi-Environnements

Le projet utilise des environnements Python sp√©cialis√©s pour optimiser les performances et √©viter les conflits de d√©pendances.

#### Emplacement centralis√© (`VENV_BASE_DIR`)

- `VENV_BASE_DIR` d√©finit la racine unique de **tous** les environnements (`env`, `tracking_env`, `audio_env`, `transnet_env`, `eos_env`).
- **Ordre de r√©solution** : variable d√©j√† export√©e dans le shell > entr√©e `.env` > dossier du projet (fallback).
- `start_workflow.sh` lit cette valeur (nettoyage des guillemets), exporte `VENV_BASE_DIR` puis d√©rive `PYTHON_VENV_EXE_ENV` attendu par `app_new.py`.
- Le backend utilise exclusivement `config.get_venv_path()` / `config.get_venv_python()` (via `WorkflowCommandsConfig`) pour construire les commandes‚ÄØ; aucune route ou script ne doit hardcoder `env/bin/python`.
- Cons√©quence : on peut d√©placer les environnements sur un SSD/NAS (ex. `/mnt/cache/venv/workflow_mediapipe`) sans modifier le code ni les scripts.

#### Environnement Principal (`env/`)
**Utilis√© par** : √âtapes 1, 2, 5, 6, 7 + Application Flask

```bash
# Activation
source env/bin/activate  # Linux/Mac
env\Scripts\activate     # Windows

# D√©pendances principales
pip install flask psutil requests opencv-python
```

**Responsabilit√©s** :
- Application web Flask
- Extraction d'archives
- Conversion vid√©o (FFmpeg)
- R√©duction JSON
- Finalisation et archivage

#### Environnement TransNet (`transnet_env/`)
**Utilis√© par** : √âtape 3 (D√©tection de sc√®nes)

```bash
# Activation
source transnet_env/bin/activate

# D√©pendances sp√©cialis√©es
pip install torch torchvision tensorflow ffmpeg-python
```

**Optimisations** :
- PyTorch optimis√© pour GPU
- TensorFlow pour TransNetV2
- Traitement par batch pour √©conomiser la m√©moire

#### Environnement Audio (`audio_env/`)
**Utilis√© par** : √âtape 4 (Analyse audio)

```bash
# Activation
source audio_env/bin/activate

# D√©pendances sp√©cialis√©es
pip install pyannote.audio torch torchaudio
```

**Fonctionnalit√©s** :
- Pyannote.audio 3.1 pour diarisation
- Support GPU/CPU adaptatif
- Mod√®les pr√©-entra√Æn√©s Hugging Face

#### Environnement Tracking (`tracking_env/`)
**Utilis√© par** : √âtape 5 (Suivi vid√©o)

```bash
# Activation
source tracking_env/bin/activate

# D√©pendances sp√©cialis√©es
pip install mediapipe opencv-python numpy
```

**Optimisations** :
- MediaPipe pour d√©tection faciale
- Multiprocessing CPU (15 workers)
- Algorithmes de tracking optimis√©s

### Gestion des Environnements

#### Script de D√©marrage (`start_workflow.sh`)

```bash
#!/bin/bash
# Activation automatique de l'environnement principal
source env/bin/activate

# V√©rification des d√©pendances
python -c "import flask, psutil; print('Dependencies OK')"

# Lancement de l'application
python app_new.py
```

#### Ex√©cution d'√âtapes avec Environnements

```python
# Dans WorkflowService
def execute_step_with_env(step_key, env_name):
    """Ex√©cute une √©tape dans son environnement d√©di√©."""
    env_path = f"{env_name}/bin/python"
    script_path = f"workflow_scripts/{step_key.lower()}/main.py"

    subprocess.run([env_path, script_path], check=True)
```

---

## Exemples d'Utilisation

### Ex√©cution Compl√®te d'un Workflow

#### 1. D√©marrage du Syst√®me

```bash
# Pr√©paration de l'environnement
# Le script start_workflow.sh g√®re automatiquement les permissions
./start_workflow.sh

# V√©rification du statut
curl http://localhost:5000/api/system_monitor
```

#### 2. Ex√©cution d'une √âtape Individuelle

```javascript
// Frontend - Ex√©cution d'√©tape
const executeStep = async (stepKey) => {
    try {
        // D√©marrage de l'√©tape
        const result = await apiService.runStep(stepKey);

        if (result.status === 'initiated') {
            // D√©marrage du monitoring
            pollingManager.startPolling(`step_${stepKey}`,
                () => updateStepStatus(stepKey), 1000);
        }
    } catch (error) {
        errorHandler.handleStepError(stepKey, error);
    }
};
```

```python
# Backend - Service d'ex√©cution
result = WorkflowService.run_step("STEP1")
if result["status"] == "initiated":
    print(f"√âtape d√©marr√©e: {result['message']}")
```

#### 3. S√©quence Personnalis√©e

```javascript
// Ex√©cution de s√©quence compl√®te
const runFullWorkflow = async () => {
    const steps = ['STEP1', 'STEP2', 'STEP3', 'STEP4', 'STEP5', 'STEP6', 'STEP7'];

    try {
        const result = await apiService.runCustomSequence(steps);

        // Monitoring de la s√©quence
        pollingManager.startPolling('sequence', async () => {
            const status = await apiService.getSequenceStatus();
            updateSequenceProgress(status);
        }, 500);

    } catch (error) {
        errorHandler.handleSequenceError(error);
    }
};
```

### Monitoring et Debugging

#### 1. Surveillance Syst√®me

```javascript
// Monitoring en temps r√©el
const startSystemMonitoring = () => {
    pollingManager.startPolling('systemStatus', async () => {
        const status = await apiService.getSystemStatus();

        // Mise √† jour de l'√©tat
        appState.setState({ systemStatus: status });

        // V√©rification des alertes
        if (status.cpu_percent > 90) {
            errorHandler.showWarning('CPU usage high');
        }
    }, 2000);
};
```

#### 2. Gestion des Logs

```python
# Backend - R√©cup√©ration de logs
logs = WorkflowService.get_step_status("STEP1", include_logs=True)
for log_entry in logs.get('logs', []):
    print(f"[{log_entry['timestamp']}] {log_entry['message']}")
```

#### 3. Cache et Performance

```python
# Utilisation du cache pour optimiser les performances
@CacheService.cached(ttl=300)
def get_expensive_data():
    # Op√©ration co√ªteuse
    return process_large_dataset()

# Statistiques de performance
stats = PerformanceService.get_performance_summary()
print(f"Temps moyen API: {stats['avg_api_time']}ms")
```

### Gestion d'Erreurs et Recovery

#### 1. Gestion d'Erreurs Frontend

```javascript
// Pattern de gestion d'erreur robuste
const robustApiCall = async (operation, ...args) => {
    try {
        const result = await operation(...args);
        errorHandler.clearErrors(operation.name);
        return result;
    } catch (error) {
        await errorHandler.handlePollingError(operation.name, error);

        // Retry automatique pour certaines erreurs
        if (error.status === 503) {
            return retryWithBackoff(operation, args);
        }
        throw error;
    }
};
```

#### 2. Recovery de S√©quence

```python
# Backend - Recovery automatique
def recover_failed_sequence():
    """R√©cup√®re une s√©quence √©chou√©e."""
    # Utiliser WorkflowState pour obtenir l'√©tat de la s√©quence
    workflow_state = WorkflowService._get_workflow_state()
    sequence_status = workflow_state.get_sequence_status()

    if sequence_status.get('status') == 'failed':
        failed_step = sequence_status.get('failed_step')
        remaining_steps = sequence_status.get('remaining_steps', [])

        # Red√©marrage depuis l'√©tape √©chou√©e
        return WorkflowService.run_custom_sequence([failed_step] + remaining_steps)

---

## Mises √† jour - 2025-09-25

### 1) Politique Dropbox-only (t√©l√©chargement automatique)
- **Comportement** : Seules les URLs Dropbox directes et proxys PHP d√©clenchent un t√©l√©chargement automatique.
- **Classification** : Les URLs sont class√©es comme `dropbox` ou `proxy_php`.
- **Autres sources** : FromSmash, SwissTransfer et autres sont ignor√©es par le syst√®me de t√©l√©chargement automatique.
- **UX attendue** : Les liens Dropbox sont t√©l√©charg√©s automatiquement, les autres sources n√©cessitent une action manuelle.

### Am√©liorations UX R√©centes

#### Simplification du Smart Upload (v4.0)
- **Avant :** Interface complexe avec recherche manuelle et boutons s√©par√©s
- **Apr√®s :** Flux en un clic avec affichage automatique des dossiers du jour
- **Impact :** R√©duction de la complexit√© cognitive et acc√©l√©ration du workflow de sauvegarde
- **Maintien :** Conservation de la logique backend s√©curis√©e et des patterns frontend √©tablis

#### Autres am√©liorations :
- Politique Dropbox-only pour les t√©l√©chargements automatiques
- Widget de monitoring syst√®me avec m√©triques GPU
- Architecture orient√©e services avec √©tat centralis√©

---

## Conclusion

Cette architecture modulaire et performante du syst√®me de workflow MediaPipe v4.0 garantit :

- **Maintenabilit√©** : S√©paration claire des responsabilit√©s
- **Performance** : Optimisations frontend et backend
- **S√©curit√©** : Protection des endpoints et validation des donn√©es
- **Scalabilit√©** : Architecture orient√©e services
- **Robustesse** : Gestion d'erreurs compl√®te et recovery automatique

Le respect de ces patterns architecturaux est essentiel pour maintenir la qualit√© et la stabilit√© du syst√®me.